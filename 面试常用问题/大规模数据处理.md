1. 海量日志数据，提取出某日访问百度次数最多的那个IP。
> 典型的分而治之 + HashMap统计，最后归并找出最大值即可(归并只需将每个文件的最大IP取出，然后将所有最大的IP再做一次比较即可)

2. 假设目前有一千万个记录（这些查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个。一个查询串的重复度越高，说明查询它的用户越多，也就是越热门。），请你统计最热门的10个查询串，要求使用的内存不能超过1G。
> 典型的TOPk问题，可以借助堆结构，将前k个设置为最小堆，然后每来一个元素就将元素与堆顶元素相比，如果比堆定元素大，那么交换，然后重新小堆化，直至所有元素遍历完成(TopK * N的时间复杂度)

3. 有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词。
> hash分治 + HashMap统计，然后每个文件内进行堆排序，找出Top100，然后将每个文件的Top100取出，进行堆排序，得到全局的Top100。

4. 有10个文件，每个文件1G，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复。要求你按照query的频度排序
> hash分治 + HashMap统计，然后每个文件内采用堆排序/快速排序的方式排序，最终进行外排序，可以进行k路归并的方法进行排序。

5. 给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？
> 经典题目求交集，内存里不能装下所有的URL：50G*64=320G，内存只有4G，当然可以采用分治的算法。
> hash分治(如采用1000个文件)，a和b都会对应1000个小文件，a的每个小文件和b的每个小文件，进行一次共同的URL计算，然后最终合并即可。

> 小文件内部的共同的URL计算，如果需要精确地话，可以采用HashSet的方式进行，如果对于精确度要求没有那么高的情况下，可以利用布隆过滤器的方式进行是否存在的判断

6. 在2.5亿个整数中找出不重复的整数，注，内存不足以容纳这2.5亿个整数。
> 在大规模数据中，bitMap是一种很好的数据结构，能将内存空间的占用降低很多，一般bitMap满足的条件为：数据量大，但状态不多。
> 此处可以采用2-BitMap的方式进行实现(每个数分配2bit的空间表示状态：00表示不存在，01表示存在1次，10表示存在多次，11表示无意义)，对于整型数来说，只需要2^32-1=1GB内存。
> 扫描2.5个数，更新bitMap中的

7. 给40亿个不重复的unsigned int的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中？
> 同样可以采用bitMap的方式，由于是unsigned int的整数，那么只需要512M的空间即可，扫描40亿个整数(分批扫描)，然后更新对应的bitMap，bitMap存在两种状态：0：不存在，1：存在。扫描完成之后，根据输入的数进行

8. 